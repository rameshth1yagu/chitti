# Project Chitti â€” Cognitive Edge Sentry

**Privacy-first embodied AI robot** performing real-time vision-language inference **entirely on-device** with **zero data persistence to disk**.

Built for EB-1A extraordinary ability petition, IEEE Senior Membership, and provisional patent.

---

## Core Innovation: Zero-Retention Architecture

All visual data is processed **exclusively in volatile RAM** (`/dev/shm` tmpfs). The VLM (Moondream via Ollama) ingests frames from RAM, produces a text-only summary, and the frame is **immediately purged**. No pixel ever touches the SSD. An automated **SSD delta audit** mathematically proves zero persistence after every inference cycle.

**Patent-eligible claim:** Privacy-first perception pipeline where sensitive sensor data (image/audio) exists ONLY in volatile memory, with cryptographic proof of purge.

---

## Hardware Stack

| Component | Specification |
|-----------|--------------|
| **Dev Machine** | Mac Pro, Apple M4 Pro |
| **Edge Brain** | NVIDIA Jetson Orin Nano SUPER (8GB LPDDR5, 1024 CUDA cores) |
| **OS** | JetPack 6.1 (Ubuntu 22.04), CUDA 12.6, cuDNN, TensorRT |
| **Chassis** | Waveshare UGV Rover (differential drive) |
| **Servos** | PCA9685 PWM driver (IÂ²C bus 1, address 0x40) |
| **Camera** | CSI camera on /dev/video0 (V4L2) |
| **Power** | 5V/4A regulated rail, separate servo power |

---

## Architecture (Phase 1)

```
~/chitti/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py            # All constants, paths, pins, thresholds
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ camera.py              # CSI camera â†’ /dev/shm capture
â”‚   â”œâ”€â”€ inference.py           # Ollama/Moondream VLM client
â”‚   â”œâ”€â”€ privacy.py             # Frame purge + SSD delta audit
â”‚   â”œâ”€â”€ pipeline.py            # Main orchestrator
â”‚   â”œâ”€â”€ zero_retention_ingress.py   # [LEGACY] Early prototype
â”‚   â”œâ”€â”€ chitti_vision_bridge.py     # [LEGACY] Monolithic pipeline
â”‚   â””â”€â”€ benchmark_suite.py          # [LEGACY] Basic benchmarks
â”œâ”€â”€ safety/                    # NEW in Phase 1
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ estop.py               # E-Stop GPIO daemon (TASK 3)
â”‚   â””â”€â”€ watchdog.py            # VRAM watchdog (TASK 3)
â”œâ”€â”€ hri/                       # Human-Robot Interaction
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tts.py                 # Ephemeral TTS (espeak â†’ aplay pipe)
â”‚   â””â”€â”€ telemetry.py           # [TODO] Local web dashboard
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ chitti_watchdog.sh     # Systemd service launcher
â”‚   â”œâ”€â”€ chitti_heal.sh         # Recovery script (cache flush + restart)
â”‚   â”œâ”€â”€ slim_jetson.sh         # System optimization
â”‚   â”œâ”€â”€ jtop_logger.py         # Basic GPU/RAM logger
â”‚   â”œâ”€â”€ verify_jetson_setup.py      # [TASK 4] System verification
â”‚   â”œâ”€â”€ setup_maxn.sh               # [TASK 4] MAXN power mode config
â”‚   â”œâ”€â”€ benchmark_baseline.py       # [TASK 4] Baseline latency benchmark
â”‚   â”œâ”€â”€ thermal_logger.py           # [TASK 5] 30-min jtop profiling
â”‚   â”œâ”€â”€ sustained_load_test.py      # [TASK 5] Stress test
â”‚   â”œâ”€â”€ analyze_thermal.py          # [TASK 5] Chart generation
â”‚   â””â”€â”€ run_phase1_profiling.sh     # [TASK 5] Full profiling orchestration
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_camera.py
â”‚   â”œâ”€â”€ test_inference.py
â”‚   â”œâ”€â”€ test_privacy.py
â”‚   â””â”€â”€ test_estop.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ evidence/
â”‚       â”œâ”€â”€ month_02/          # Early evidence artifacts
â”‚       â””â”€â”€ phase_01/          # Phase 1 benchmarks, logs, charts
â”œâ”€â”€ CLAUDE.md                  # Project prompt for Claude Code
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ setup.py                   # Package installation config
```

---

## Data Flow: Complete Perception Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PERCEPTION PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  CSI Camera (/dev/video0)
         â”‚
         â”‚ cv2.VideoCapture() â†’ NumPy array (RAM)
         â–¼
  /dev/shm/chitti/frame.jpg  â—„â”€â”€ VOLATILE RAM (tmpfs)
         â”‚
         â”‚ base64 encode
         â–¼
  Ollama REST API (localhost:11434)
         â”‚
         â”‚ Moondream VLM inference (~3-5s)
         â–¼
  Text description (e.g., "A laptop on a desk")
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                      â”‚
         â–¼                      â–¼
  espeak TTS           SSD Delta Audit
  (ephemeral pipe)     (shutil.disk_usage)
         â”‚                      â”‚
         â”‚                      â”‚
         â–¼                      â–¼
  aplay                 ssd_final - ssd_initial == 0
  (speakers)            âœ… ZERO RETENTION VERIFIED
         â”‚
         â–¼
  os.remove(/dev/shm/chitti/frame.jpg)
         â”‚
         â–¼
  ğŸ”’ PRIVACY CYCLE COMPLETE
```

**Key property:** At no point does image data touch `/home`, `/var`, or any SSD path. Audio is piped kernel-to-kernel (espeak â†’ aplay) with no intermediate file.

---

## Quick Start (Jetson Orin Nano)

### 1. Clone Repository
```bash
cd ~
git clone https://github.com/rameshth1yagu/chitti.git
cd chitti
```

### 2. Install System Dependencies
```bash
sudo apt-get update && sudo apt-get install -y \
  espeak-ng alsa-utils i2c-tools v4l-utils python3-jetson-gpio
```

### 3. Install Python Dependencies
```bash
pip3 install -e .
```

### 4. Configure Jetson for MAXN Performance
```bash
# [TASK 4] This script will be created in Phase 1
# For now, manual setup:
sudo nvpmodel -m 0              # MAXN power mode (25W)
sudo jetson_clocks              # Pin clocks at max frequency
```

### 5. Start Ollama with Privacy Env Vars
```bash
# Use the existing watchdog service
sudo systemctl enable chitti-watchdog.service
sudo systemctl start chitti-watchdog.service

# Or manually:
export GGML_CUDA_ENABLE_UNIFIED_MEMORY=1
export OLLAMA_KEEP_ALIVE=0
ollama serve &

# Pull Moondream model
ollama pull moondream
```

### 6. Run Single Perception Cycle
```bash
python3 -m core.pipeline
```

**Expected output:**
```
============================================================
Chitti Perception Cycle Complete
============================================================
Timestamp: 2026-02-15T14:23:45.123456
Total Latency: 4.521s

Chitti sees: A person sitting at a desk with a laptop.
Inference Latency: 3.842s

SSD Audit:
  Initial: 24.315GB
  Final: 24.315GB
  Delta: 0.000GB
  Zero Retention: âœ… VERIFIED
============================================================
```

---

## Current Status (Phase 1)

- [x] **Privacy architecture**: /dev/shm pipeline working, ephemeral TTS fixed
- [x] **Modular refactor**: config/, core/, hri/, safety/, tests/ structure
- [x] **Ollama integration**: Moondream VLM functional, hardened service
- [x] **SSD audit**: Delta verification implemented
- [ ] **E-Stop**: GPIO daemon (TASK 3)
- [ ] **VRAM watchdog**: OOM recovery with E-Stop integration (TASK 3)
- [ ] **Jetson config**: MAXN setup + verification scripts (TASK 4)
- [ ] **Baseline benchmark**: 10-run statistical analysis (TASK 4)
- [ ] **Thermal profiling**: 30-min jtop logging + charts (TASK 5)

**Next milestone:** Complete TASK 3 (E-Stop & Safety Failsafe)

---

## Tech Stack

| Category | Technology |
|----------|-----------|
| **Language** | Python 3.10+ (primary), Bash (automation) |
| **AI Runtime** | Ollama (localhost:11434) serving Moondream 1.6B |
| **Vision** | OpenCV (cv2) for frame capture |
| **GPIO/Servos** | Jetson.GPIO, PCA9685 (IÂ²C), adafruit-servokit |
| **Monitoring** | jetson-stats (jtop) for telemetry |
| **TTS** | espeak-ng (ephemeral audio pipeline) |
| **Testing** | pytest with mocked GPIO |

---

## Code Standards

- âœ… **Module docstrings**: Every file explains purpose and EB-1A relevance
- âœ… **Type hints**: All public function signatures annotated
- âœ… **Structured logging**: JSON format for machine-parseable evidence
- âœ… **Error handling**: Try/except on all I/O operations
- âœ… **Privacy enforcement**: No image/audio writes to SSD paths
- âœ… **Centralized config**: All constants in `config/settings.py`
- âœ… **Importable modules**: No circular dependencies

---

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=core --cov=hri --cov-report=html

# Test specific module
pytest tests/test_camera.py -v
```

**Note:** Hardware-dependent tests (camera, GPIO) require running ON Jetson. Use `pytest -m "not hardware"` to skip hardware tests during development.

---

## Evidence Artifacts (EB-1A / IEEE)

All evidence artifacts are organized in `docs/evidence/`:

```
docs/evidence/
â”œâ”€â”€ month_02/                      # Early development logs
â”‚   â”œâ”€â”€ chitti_watchdog_service_spec.md
â”‚   â”œâ”€â”€ deploy_ollama_hardening.md
â”‚   â”œâ”€â”€ vlm_selection_verification.md
â”‚   â””â”€â”€ inference_latency_benchmarks.md
â””â”€â”€ phase_01/                      # Phase 1 deliverables (TASKS 4-6)
    â”œâ”€â”€ jetson_setup_verification.json
    â”œâ”€â”€ baseline_latency.json
    â”œâ”€â”€ thermal_profile.csv
    â”œâ”€â”€ thermal_profile_chart.png
    â”œâ”€â”€ sustained_load_log.csv
    â”œâ”€â”€ power_rail_template.md
    â””â”€â”€ EVIDENCE_INDEX.md
```

---

## License

MIT License - This is research/portfolio code. See LICENSE file.

---

## Contact

**Ramesh Thiyagu**
GitHub: [@rameshth1yagu](https://github.com/rameshth1yagu)
Project: EB-1A Extraordinary Ability Petition (AI/Robotics)

---

**Built with Claude Code** â€” [claude.com/claude-code](https://claude.com/claude-code)